# -*- coding: utf-8 -*-
"""Python End-to-end Multiclass Classification Project.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1MG19Cy3xhGUPIcRwtq3wjZO3Zz6SkjCm
"""

# importing pandas
import pandas as pd

# using pandas read_csv function to load the dataset
df = pd.read_csv("RTA Dataset.csv")
df.head()

# print the dataset information
df.info()

# Find the number of missing values present in each column
df.isnull().sum()

# target variable classes counts and bar plot
import matplotlib.pyplot as plt
print(df['Accident_severity'].value_counts())
df['Accident_severity'].value_counts().plot(kind='bar')

# Education levels of car drivers
df['Educational_level'].value_counts().plot(kind='bar')

pip install git+https://github.com/amueller/dabl/

import dabl

dabl.plot(df, target_col='Accident_severity')

import seaborn as sns

stackup_username = "maulanairfanf"
print("Submission by:", stackup_username)

# plot the bar plot of road_surface_type and accident severity feature
plt.figure(figsize=(6,5))
sns.countplot(x="Road_surface_type", hue="Accident_severity", data=df)
plt.xlabel("Road surface type")
plt.xticks(rotation=60)
plt.show()

# convert object type column into datetime datatype column
df['Time'] = pd.to_datetime(df['Time'])

# Extrating 'Hour_of_Day' feature from the Time column
new_df = df.copy()
new_df['Hour_of_Day'] = new_df['Time'].dt.hour
n_df = new_df.drop('Time', axis=1)
n_df.head()

# feature selection based on visualization (to_be_continue)
features = ['Day_of_week','Number_of_vehicles_involved','Number_of_casualties','Area_accident_occured',
      'Types_of_Junction','Age_band_of_driver','Sex_of_driver','Educational_level',
      'Vehicle_driver_relation','Type_of_vehicle','Driving_experience','Service_year_of_vehicle','Type_of_collision',
      'Sex_of_casualty','Age_band_of_casualty','Cause_of_accident','Hour_of_Day']
len(features)

# new dataframe generated
featureset_df = n_df[features]
target = n_df['Accident_severity']

# metadata of the new sub dataset
featureset_df.info()

feature_df = featureset_df.copy()

# NaN are missing because service info might not be available, we will fill as 'Unknown'
feature_df['Service_year_of_vehicle'] = feature_df['Service_year_of_vehicle'].fillna('Unknown')
feature_df['Types_of_Junction'] = feature_df['Types_of_Junction'].fillna('Unknown')
feature_df['Area_accident_occured'] = feature_df['Area_accident_occured'].fillna('Unknown')
feature_df['Driving_experience'] = feature_df['Driving_experience'].fillna('unknown')
feature_df['Type_of_vehicle'] = feature_df['Type_of_vehicle'].fillna('Other')
feature_df['Vehicle_driver_relation'] = feature_df['Vehicle_driver_relation'].fillna('Unknown')
feature_df['Educational_level'] = feature_df['Educational_level'].fillna('Unknown')
feature_df['Type_of_collision'] = feature_df['Type_of_collision'].fillna('Unknown')

# features information
feature_df.info()

# setting input features X and target y 
X = feature_df[features] # here features are selected from 'object' datatype
y = n_df['Accident_severity']

# we will use pandas get_dummies method for on-hot encoding
encoded_df = pd.get_dummies(X, drop_first=True)
encoded_df.shape

# import labelencoder from sklearn.preprocessing
from sklearn.preprocessing import LabelEncoder

# create labelencoder object
lb = LabelEncoder()
lb.fit(y)
y_encoded = lb.transform(y)
print("Encoded labels:",lb.classes_)
y_en = pd.Series(y_encoded)

# feature selection method using chi2 for categorical output, categorical input
from sklearn.feature_selection import SelectKBest, chi2
fs = SelectKBest(chi2, k=50)
X_new = fs.fit_transform(encoded_df, y_en)

# Take the selected features
cols = fs.get_feature_names_out()

# convert selected features into dataframe
fs_df = pd.DataFrame(X_new, columns=cols)

import numpy as np

# importing the SMOTENC object from imblearn library 
from imblearn.over_sampling import SMOTENC

# categorical features for SMOTENC technique for categorical features
n_cat_index = np.array(range(3,50))

# creating smote object with SMOTENC class
smote = SMOTENC(categorical_features=n_cat_index, random_state=42, n_jobs=True)
X_n, y_n = smote.fit_resample(fs_df,y_en)

# print the shape of new upsampled dataset
X_n.shape, y_n.shape

# print the target classes distribution
print(y_n.value_counts())

# import the necessary libraries
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import confusion_matrix, classification_report, f1_score

# train and test split and building baseline model to predict target features
X_trn, X_tst, y_trn, y_tst = train_test_split(X_n, y_n, test_size=0.2, random_state=42)

# modelling using random forest baseline
rf = RandomForestClassifier(n_estimators=800, max_depth=20, random_state=42)
rf.fit(X_trn, y_trn)

# predicting on test data
predics = rf.predict(X_tst)

# train score 
rf.score(X_trn, y_trn)

stackup_username = "maulanairfanf"
print("Submission by:", stackup_username)

# classification report on test dataset
classif_re = classification_report(y_tst,predics)
print(classif_re)

# f1_score of the model
f1score = f1_score(y_tst,predics, average='weighted')
print(f1score)

# selecting 7 categorical features from the dataframe
import joblib
from sklearn.preprocessing import OrdinalEncoder

new_fea_df = feature_df[['Type_of_collision','Age_band_of_driver','Sex_of_driver',
    'Educational_level','Service_year_of_vehicle','Day_of_week','Area_accident_occured']]

oencoder2 = OrdinalEncoder()
encoded_df3 = pd.DataFrame(oencoder2.fit_transform(new_fea_df))
encoded_df3.columns = new_fea_df.columns

# save the ordinal encoder object for inference pipeline
joblib.dump(oencoder2, "ordinal_encoder2.joblib")

# final dataframe to be trained for model inference
s_final_df = pd.concat([feature_df[['Number_of_vehicles_involved','Number_of_casualties','Hour_of_Day']],encoded_df3], axis=1)

# train and test split and building baseline model to predict target features
X_trn2, X_tst2, y_trn2, y_tst2 = train_test_split(s_final_df, y_en, test_size=0.2, random_state=42)

# modelling using random forest baseline
rf = RandomForestClassifier(n_estimators=700, max_depth=20, random_state=42)
rf.fit(X_trn2, y_trn2)

# save the model object
joblib.dump(rf, "rta_model_deploy3.joblib", compress=9)

pip install -r requirements.txt

# import all the app dependencies
import pandas as pd
import numpy as np
import sklearn
import streamlit as st
import joblib
import matplotlib
from IPython import get_ipython
from PIL import Image

# load the encoder and model object
model = joblib.load("rta_model_deploy3.joblib")
encoder = joblib.load("ordinal_encoder2.joblib")

st.set_option('deprecation.showPyplotGlobalUse', False)

# 1: serious injury, 2: Slight injury, 0: Fatal Injury

st.set_page_config(page_title="Accident Severity Prediction App",
        page_icon="ðŸš§", layout="wide")

#creating option list for dropdown menu
options_day = ['Sunday', "Monday", "Tuesday", "Wednesday", "Thursday", "Friday", "Saturday"]
options_age = ['18-30', '31-50', 'Over 51', 'Unknown', 'Under 18']

# number of vehicle involved: range of 1 to 7
# number of casualties: range of 1 to 8
# hour of the day: range of 0 to 23

options_types_collision = ['Vehicle with vehicle collision','Collision with roadside objects',
              'Collision with pedestrians','Rollover','Collision with animals',
              'Unknown','Collision with roadside-parked vehicles','Fall from vehicles',
              'Other','With Train']

options_sex = ['Male','Female','Unknown']

options_education_level = ['Junior high school','Elementary school','High school',
              'Unknown','Above high school','Writing & reading','Illiterate']

options_services_year = ['Unknown','2-5yrs','Above 10yr','5-10yrs','1-2yr','Below 1yr']

options_acc_area = ['Other', 'Office areas', 'Residential areas', ' Church areas',
    ' Industrial areas', 'School areas', ' Recreational areas',
    ' Outside rural areas', ' Hospital areas', ' Market areas',
    'Rural village areas', 'Unknown', 'Rural village areasOffice areas',
    'Recreational areas']

# features list
features = ['Number_of_vehicles_involved','Number_of_casualties','Hour_of_Day','Type_of_collision','Age_band_of_driver','Sex_of_driver',
    'Educational_level','Service_year_of_vehicle','Day_of_week','Area_accident_occured']

# Give a title to web app using html syntax
st.markdown("<h1 style='text-align: center;'>Accident Severity Prediction App ðŸš§</h1>", unsafe_allow_html=True)

# define a main() function to take inputs from user in form based approach
def main():
    with st.form("road_traffic_severity_form"):
       st.subheader("Please enter the following inputs:")
        
       No_vehicles = st.slider("Number of vehicles involved:",1,7, value=0, format="%d")
       No_casualties = st.slider("Number of casualties:",1,8, value=0, format="%d")
       Hour = st.slider("Hour of the day:", 0, 23, value=0, format="%d")
       collision = st.selectbox("Type of collision:",options=options_types_collision)
       Age_band = st.selectbox("Driver age group?:", options=options_age)
       Sex = st.selectbox("Sex of the driver:", options=options_sex)
       Education = st.selectbox("Education of driver:",options=options_education_level)
       service_vehicle = st.selectbox("Service year of vehicle:", options=options_services_year)
       Day_week = st.selectbox("Day of the week:", options=options_day)
       Accident_area = st.selectbox("Area of accident:", options=options_acc_area)
        
       submit = st.form_submit_button("Predict")

# encode using ordinal encoder and predict
    if submit:
       input_array = np.array([collision,
                  Age_band,Sex,Education,service_vehicle,
                  Day_week,Accident_area], ndmin=2)
        
       encoded_arr = list(encoder.transform(input_array).ravel())
        
       num_arr = [No_vehicles,No_casualties,Hour]
       pred_arr = np.array(num_arr + encoded_arr).reshape(1,-1)        
      
# predict the target from all the input features
       prediction = model.predict(pred_arr)
        
       if prediction == 0:
           st.write(f"The severity prediction is fatal injuryâš ")
       elif prediction == 1:
           st.write(f"The severity prediction is serious injury")
       else:
           st.write(f"The severity prediction is slight injury")
        
       st.write("Developed By: Avi kumar Talaviya")
       st.markdown("""Reach out to me on: [Twitter](https://twitter.com/avikumart_) |
       [Linkedin](https://www.linkedin.com/in/avi-kumar-talaviya-739153147/) |
       [Kaggle](https://www.kaggle.com/avikumart) 
       """)

a,b,c = st.columns([0.2,0.6,0.2])
with b:
 st.image("banner-picture.jpeg", use_column_width=True)


# description about the project and code files       
st.subheader("ðŸ§¾Description:")
st.text("""This data set is collected from Addis Ababa Sub-city police departments for master's research work. 
The data set has been prepared from manual records of road traffic accidents of the year 2017-20. 
All the sensitive information has been excluded during data encoding and finally it has 32 features and 12316 instances of the accident.
Then it is preprocessed and for identification of major causes of the accident by analyzing it using different machine learning classification algorithms.
""")

st.markdown("Source of the dataset: [Click Here](https://www.narcis.nl/dataset/RecordID/oai%3Aeasy.dans.knaw.nl%3Aeasy-dataset%3A191591)")

st.subheader("ðŸ§­ Problem Statement:")
st.text("""The target feature is Accident_severity which is a multi-class variable. 
The task is to classify this variable based on the other 31 features step-by-step by going through each day's task. 
The metric for evaluation will be f1-score
""")

st.markdown("Please find GitHub repository link of project: [Click Here](https://github.com/avikumart/Road-Traffic-Severity-Classification-Project)")          
  
# run the main function        
if __name__ == '__main__':
  main()